{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tugas 7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIX7D7rm6MwP"
      },
      "source": [
        "Untuk mencatat execution time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZM4DwuthJ7-",
        "outputId": "fde1ec3d-90ae-4723-ffb4-5251b3df9c99"
      },
      "source": [
        "!pip install ipython-autotime\r\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipython-autotime) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (50.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.6.0)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 2.54 s (started: 2020-12-22 04:51:19 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP_OckyJ6WIB"
      },
      "source": [
        "Import pandas untuk dataframe dan numpy untuk pembulatan<br>\r\n",
        "Import train_test_split untuk mengatur test size, scaler untuk normalisasi, dan accuracy untuk akurasi<br>\r\n",
        "Import keras untuk CNN-nya<br>\r\n",
        "Import pyplot untuk plotting grafik"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5wL55kONmOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04385674-4ce2-441d-d308-26879065d6f2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 4 ms (started: 2020-12-22 01:55:36 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H86cK_eJ7hJE"
      },
      "source": [
        "Meng-import file csv dan melihat isinya\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "JjnN5Jh_d5zF",
        "outputId": "415ca67f-dd48-411d-9698-26ff56a786e8"
      },
      "source": [
        "df = pd.read_csv('data.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Make</th>\n",
              "      <th>Model</th>\n",
              "      <th>Year</th>\n",
              "      <th>Engine Fuel Type</th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>Transmission Type</th>\n",
              "      <th>Driven_Wheels</th>\n",
              "      <th>Number of Doors</th>\n",
              "      <th>Market Category</th>\n",
              "      <th>Vehicle Size</th>\n",
              "      <th>Vehicle Style</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>MSRP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series M</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Factory Tuner,Luxury,High-Performance</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>46135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Luxury,Performance</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Convertible</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>40650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Luxury,High-Performance</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "      <td>36350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Luxury,Performance</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Coupe</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>29450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BMW</td>\n",
              "      <td>1 Series</td>\n",
              "      <td>2011</td>\n",
              "      <td>premium unleaded (required)</td>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>MANUAL</td>\n",
              "      <td>rear wheel drive</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Luxury</td>\n",
              "      <td>Compact</td>\n",
              "      <td>Convertible</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>34500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Make       Model  Year  ... city mpg  Popularity   MSRP\n",
              "0  BMW  1 Series M  2011  ...       19        3916  46135\n",
              "1  BMW    1 Series  2011  ...       19        3916  40650\n",
              "2  BMW    1 Series  2011  ...       20        3916  36350\n",
              "3  BMW    1 Series  2011  ...       18        3916  29450\n",
              "4  BMW    1 Series  2011  ...       18        3916  34500\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "text": [
            "time: 93.7 ms (started: 2020-12-22 01:11:34 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul7LNxYu8xH9"
      },
      "source": [
        "Mengambil hanya kolom yang bertipe numerik saja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH4xzAjgeWMP",
        "outputId": "41f2d574-f6b4-474a-e028-872811afea99"
      },
      "source": [
        "numeric = []\n",
        "for col in df.drop(columns=['Year','Number of Doors']).columns:\n",
        "  print(df[col].dtypes)\n",
        "  if df[col].dtypes != 'object':\n",
        "    numeric.append(col)\n",
        "numeric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n",
            "object\n",
            "object\n",
            "float64\n",
            "float64\n",
            "object\n",
            "object\n",
            "object\n",
            "object\n",
            "object\n",
            "int64\n",
            "int64\n",
            "int64\n",
            "int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Engine HP',\n",
              " 'Engine Cylinders',\n",
              " 'highway MPG',\n",
              " 'city mpg',\n",
              " 'Popularity',\n",
              " 'MSRP']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "stream",
          "text": [
            "time: 12.4 ms (started: 2020-12-22 01:32:33 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1o1uLKV9p42"
      },
      "source": [
        "Pada target (MSRP) diubah menjadi kategorikal (cheap & expensive), kemudian diubah menjadi numerik diskrit (0: cheap & 1: expensive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Mw2cZDSDegx2",
        "outputId": "ab350d3c-d534-4885-bdf0-f2e740658ba1"
      },
      "source": [
        "df_num = df[numeric]\n",
        "df_num['MSRP'] = pd.qcut(df_num['MSRP'], 2, labels=['cheap', 'expensive'])\n",
        "df_num['MSRP'].replace({'cheap': 0, 'expensive': 1}, inplace=True)\n",
        "df_num.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "      <th>MSRP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Engine HP  Engine Cylinders  highway MPG  city mpg  Popularity  MSRP\n",
              "0      335.0               6.0           26        19        3916     1\n",
              "1      300.0               6.0           28        19        3916     1\n",
              "2      300.0               6.0           28        20        3916     1\n",
              "3      230.0               6.0           28        18        3916     0\n",
              "4      230.0               6.0           28        18        3916     1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "stream",
          "text": [
            "time: 32.2 ms (started: 2020-12-22 01:32:36 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuQKebmcBStF"
      },
      "source": [
        "Menghilangkan row yang memiliki missing value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSfD2kLMe2oG",
        "outputId": "99d95235-0cb0-40f2-c3f5-6145121225f1"
      },
      "source": [
        "df_num.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 5.76 ms (started: 2020-12-22 01:32:39 +00:00)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdeBPfB-Bsvw"
      },
      "source": [
        "Membagi data menjadi fitur (X) dan target (y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "FoFOwJJ4Bq_j",
        "outputId": "0710d460-4f9c-4784-9647-54bea98ec1d2"
      },
      "source": [
        "X, y = df_num.drop(columns=['MSRP']), df_num['MSRP']\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engine HP</th>\n",
              "      <th>Engine Cylinders</th>\n",
              "      <th>highway MPG</th>\n",
              "      <th>city mpg</th>\n",
              "      <th>Popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>335.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>19</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>20</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>230.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11909</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11910</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11911</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11912</th>\n",
              "      <td>300.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11913</th>\n",
              "      <td>221.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26</td>\n",
              "      <td>17</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11816 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Engine HP  Engine Cylinders  highway MPG  city mpg  Popularity\n",
              "0          335.0               6.0           26        19        3916\n",
              "1          300.0               6.0           28        19        3916\n",
              "2          300.0               6.0           28        20        3916\n",
              "3          230.0               6.0           28        18        3916\n",
              "4          230.0               6.0           28        18        3916\n",
              "...          ...               ...          ...       ...         ...\n",
              "11909      300.0               6.0           23        16         204\n",
              "11910      300.0               6.0           23        16         204\n",
              "11911      300.0               6.0           23        16         204\n",
              "11912      300.0               6.0           23        16         204\n",
              "11913      221.0               6.0           26        17          61\n",
              "\n",
              "[11816 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "stream",
          "text": [
            "time: 26.9 ms (started: 2020-12-22 01:32:41 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2weQqeQQCgSM"
      },
      "source": [
        "Melakukan normalisasi pada setiap fitur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO72qqRxfEZt",
        "outputId": "a92ff0cc-f018-4554-f8b8-d0ef3fc97349"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29598309, 0.375     , 0.04093567, 0.09230769, 0.69213086],\n",
              "       [0.2589852 , 0.375     , 0.04678363, 0.09230769, 0.69213086],\n",
              "       [0.2589852 , 0.375     , 0.04678363, 0.1       , 0.69213086],\n",
              "       ...,\n",
              "       [0.2589852 , 0.375     , 0.03216374, 0.06923077, 0.0357206 ],\n",
              "       [0.2589852 , 0.375     , 0.03216374, 0.06923077, 0.0357206 ],\n",
              "       [0.17547569, 0.375     , 0.04093567, 0.07692308, 0.01043324]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "stream",
          "text": [
            "time: 10.1 ms (started: 2020-12-22 01:32:43 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pncn3sl2D6Px"
      },
      "source": [
        "Membagi data menjadi train dan test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJZJR8-efP0c",
        "outputId": "09b857bf-4421-43c5-acfe-86e399dbc508"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1, random_state=42)\n",
        "print(len(X_train), len(y_train), len(X_test), len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10634 10634 1182 1182\n",
            "time: 7.26 ms (started: 2020-12-22 01:32:45 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rrfi0t8Pfc7g"
      },
      "source": [
        "Mengubah dataframe menjadi 3 dimensi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FGWj62WfeTD",
        "outputId": "55680522-1159-41a4-fc8e-35ff97096f55"
      },
      "source": [
        "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_train_reshaped.shape[1:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "stream",
          "text": [
            "time: 4.36 ms (started: 2020-12-22 01:39:29 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bncmyDZQf0uy",
        "outputId": "015ca808-02f4-44b8-aba9-2db4a6094387"
      },
      "source": [
        "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_test_reshaped.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1182, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "stream",
          "text": [
            "time: 3.52 ms (started: 2020-12-22 01:39:31 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLMEKq6hG67L"
      },
      "source": [
        "Menambahkan conv layer 1, conv layer 2, dan output layer pada CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN4mM_SIf5eS",
        "outputId": "3680ffd4-98f3-4934-afa1-171bcf3f5ce4"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(32, 4, input_shape=X_train_reshaped.shape[1:3], activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(1))\n",
        "\n",
        "model.add(Conv1D(16, 2, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_28 (Conv1D)           (None, 2, 32)             160       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 2, 32)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_14 (MaxPooling (None, 2, 32)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_29 (Conv1D)           (None, 1, 16)             1040      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 1, 16)             0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_15 (MaxPooling (None, 1, 16)             0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,217\n",
            "Trainable params: 1,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "time: 81.9 ms (started: 2020-12-22 04:41:59 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuuUo5tyKzRU"
      },
      "source": [
        "Menambahkan early stopping untuk menghentikan iterasi ketika setelah beberapa iterasi akurasi tidak bertambah"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nou5N7CVgD1u",
        "outputId": "2e5c0a53-c208-4822-c8a6-1cf51d2d71c7"
      },
      "source": [
        "time_start = time.time()\n",
        "lr = 0.01\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "early_stopping_monitor = EarlyStopping(\n",
        "    monitor='accuracy',\n",
        "    min_delta=0,\n",
        "    patience=100,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics='accuracy')\n",
        "\n",
        "history = model.fit(X_train_reshaped, y_train,\n",
        "          epochs=1000, \n",
        "          verbose=1,\n",
        "          validation_data=(X_test_reshaped, y_test),\n",
        "          callbacks=[early_stopping_monitor])\n",
        "\n",
        "time_end = time.time()\n",
        "\n",
        "print('Time elapsed : ' + str(time_end - time_start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7184 - val_loss: 0.3308 - val_accuracy: 0.8782\n",
            "Epoch 2/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3653 - accuracy: 0.8537 - val_loss: 0.3101 - val_accuracy: 0.8841\n",
            "Epoch 3/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8647 - val_loss: 0.3023 - val_accuracy: 0.8824\n",
            "Epoch 4/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8575 - val_loss: 0.2989 - val_accuracy: 0.8841\n",
            "Epoch 5/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3488 - accuracy: 0.8558 - val_loss: 0.3125 - val_accuracy: 0.8672\n",
            "Epoch 6/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3416 - accuracy: 0.8625 - val_loss: 0.3011 - val_accuracy: 0.8697\n",
            "Epoch 7/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8613 - val_loss: 0.3083 - val_accuracy: 0.8587\n",
            "Epoch 8/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3380 - accuracy: 0.8622 - val_loss: 0.3170 - val_accuracy: 0.8706\n",
            "Epoch 9/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3435 - accuracy: 0.8579 - val_loss: 0.3057 - val_accuracy: 0.8579\n",
            "Epoch 10/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8653 - val_loss: 0.3059 - val_accuracy: 0.8731\n",
            "Epoch 11/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8603 - val_loss: 0.2959 - val_accuracy: 0.8748\n",
            "Epoch 12/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8676 - val_loss: 0.2978 - val_accuracy: 0.8816\n",
            "Epoch 13/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.8685 - val_loss: 0.2978 - val_accuracy: 0.8714\n",
            "Epoch 14/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8615 - val_loss: 0.2953 - val_accuracy: 0.8832\n",
            "Epoch 15/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8666 - val_loss: 0.3124 - val_accuracy: 0.8731\n",
            "Epoch 16/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8639 - val_loss: 0.3017 - val_accuracy: 0.8562\n",
            "Epoch 17/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8688 - val_loss: 0.2976 - val_accuracy: 0.8849\n",
            "Epoch 18/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8637 - val_loss: 0.2957 - val_accuracy: 0.8756\n",
            "Epoch 19/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8700 - val_loss: 0.3007 - val_accuracy: 0.8824\n",
            "Epoch 20/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8655 - val_loss: 0.3037 - val_accuracy: 0.8689\n",
            "Epoch 21/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.8705 - val_loss: 0.3000 - val_accuracy: 0.8655\n",
            "Epoch 22/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8622 - val_loss: 0.3267 - val_accuracy: 0.8706\n",
            "Epoch 23/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8669 - val_loss: 0.3003 - val_accuracy: 0.8849\n",
            "Epoch 24/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3128 - accuracy: 0.8647 - val_loss: 0.2945 - val_accuracy: 0.8841\n",
            "Epoch 25/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3199 - accuracy: 0.8660 - val_loss: 0.3018 - val_accuracy: 0.8816\n",
            "Epoch 26/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8613 - val_loss: 0.3051 - val_accuracy: 0.8689\n",
            "Epoch 27/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8612 - val_loss: 0.2952 - val_accuracy: 0.8773\n",
            "Epoch 28/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8641 - val_loss: 0.2958 - val_accuracy: 0.8723\n",
            "Epoch 29/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8677 - val_loss: 0.2949 - val_accuracy: 0.8816\n",
            "Epoch 30/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3205 - accuracy: 0.8678 - val_loss: 0.2952 - val_accuracy: 0.8824\n",
            "Epoch 31/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8719 - val_loss: 0.2940 - val_accuracy: 0.8849\n",
            "Epoch 32/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.8756 - val_loss: 0.2970 - val_accuracy: 0.8816\n",
            "Epoch 33/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8613 - val_loss: 0.2974 - val_accuracy: 0.8672\n",
            "Epoch 34/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8630 - val_loss: 0.3029 - val_accuracy: 0.8672\n",
            "Epoch 35/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8701 - val_loss: 0.2887 - val_accuracy: 0.8858\n",
            "Epoch 36/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3228 - accuracy: 0.8639 - val_loss: 0.2985 - val_accuracy: 0.8807\n",
            "Epoch 37/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8664 - val_loss: 0.3014 - val_accuracy: 0.8663\n",
            "Epoch 38/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3223 - accuracy: 0.8621 - val_loss: 0.2911 - val_accuracy: 0.8841\n",
            "Epoch 39/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3257 - accuracy: 0.8602 - val_loss: 0.2913 - val_accuracy: 0.8832\n",
            "Epoch 40/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8691 - val_loss: 0.3028 - val_accuracy: 0.8663\n",
            "Epoch 41/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8590 - val_loss: 0.2949 - val_accuracy: 0.8832\n",
            "Epoch 42/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8666 - val_loss: 0.3173 - val_accuracy: 0.8672\n",
            "Epoch 43/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3200 - accuracy: 0.8677 - val_loss: 0.2951 - val_accuracy: 0.8832\n",
            "Epoch 44/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.8732 - val_loss: 0.2887 - val_accuracy: 0.8866\n",
            "Epoch 45/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8718 - val_loss: 0.2925 - val_accuracy: 0.8832\n",
            "Epoch 46/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3196 - accuracy: 0.8714 - val_loss: 0.3023 - val_accuracy: 0.8748\n",
            "Epoch 47/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.8685 - val_loss: 0.2994 - val_accuracy: 0.8596\n",
            "Epoch 48/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8663 - val_loss: 0.2911 - val_accuracy: 0.8892\n",
            "Epoch 49/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8657 - val_loss: 0.2937 - val_accuracy: 0.8858\n",
            "Epoch 50/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3155 - accuracy: 0.8700 - val_loss: 0.2937 - val_accuracy: 0.8587\n",
            "Epoch 51/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8609 - val_loss: 0.2973 - val_accuracy: 0.8832\n",
            "Epoch 52/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8626 - val_loss: 0.2922 - val_accuracy: 0.8824\n",
            "Epoch 53/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8635 - val_loss: 0.2952 - val_accuracy: 0.8841\n",
            "Epoch 54/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3170 - accuracy: 0.8689 - val_loss: 0.3036 - val_accuracy: 0.8849\n",
            "Epoch 55/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8582 - val_loss: 0.3059 - val_accuracy: 0.8655\n",
            "Epoch 56/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3170 - accuracy: 0.8713 - val_loss: 0.3096 - val_accuracy: 0.8824\n",
            "Epoch 57/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8695 - val_loss: 0.2941 - val_accuracy: 0.8739\n",
            "Epoch 58/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.8668 - val_loss: 0.2922 - val_accuracy: 0.8841\n",
            "Epoch 59/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8671 - val_loss: 0.3118 - val_accuracy: 0.8604\n",
            "Epoch 60/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.8681 - val_loss: 0.2989 - val_accuracy: 0.8613\n",
            "Epoch 61/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8679 - val_loss: 0.3011 - val_accuracy: 0.8866\n",
            "Epoch 62/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8646 - val_loss: 0.2891 - val_accuracy: 0.8832\n",
            "Epoch 63/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3113 - accuracy: 0.8689 - val_loss: 0.2919 - val_accuracy: 0.8824\n",
            "Epoch 64/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3167 - accuracy: 0.8691 - val_loss: 0.3122 - val_accuracy: 0.8765\n",
            "Epoch 65/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8687 - val_loss: 0.3058 - val_accuracy: 0.8596\n",
            "Epoch 66/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8664 - val_loss: 0.2912 - val_accuracy: 0.8841\n",
            "Epoch 67/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3211 - accuracy: 0.8705 - val_loss: 0.2921 - val_accuracy: 0.8841\n",
            "Epoch 68/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3165 - accuracy: 0.8689 - val_loss: 0.3005 - val_accuracy: 0.8680\n",
            "Epoch 69/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8643 - val_loss: 0.2997 - val_accuracy: 0.8832\n",
            "Epoch 70/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8632 - val_loss: 0.2823 - val_accuracy: 0.8849\n",
            "Epoch 71/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3156 - accuracy: 0.8688 - val_loss: 0.2845 - val_accuracy: 0.8832\n",
            "Epoch 72/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3075 - accuracy: 0.8671 - val_loss: 0.2930 - val_accuracy: 0.8714\n",
            "Epoch 73/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3164 - accuracy: 0.8717 - val_loss: 0.2895 - val_accuracy: 0.8773\n",
            "Epoch 74/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.8732 - val_loss: 0.2908 - val_accuracy: 0.8697\n",
            "Epoch 75/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8662 - val_loss: 0.2912 - val_accuracy: 0.8799\n",
            "Epoch 76/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8649 - val_loss: 0.2856 - val_accuracy: 0.8816\n",
            "Epoch 77/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3142 - accuracy: 0.8666 - val_loss: 0.2864 - val_accuracy: 0.8866\n",
            "Epoch 78/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3193 - accuracy: 0.8675 - val_loss: 0.2853 - val_accuracy: 0.8807\n",
            "Epoch 79/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3182 - accuracy: 0.8662 - val_loss: 0.2883 - val_accuracy: 0.8866\n",
            "Epoch 80/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3172 - accuracy: 0.8679 - val_loss: 0.3017 - val_accuracy: 0.8816\n",
            "Epoch 81/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8726 - val_loss: 0.2899 - val_accuracy: 0.8680\n",
            "Epoch 82/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8667 - val_loss: 0.2923 - val_accuracy: 0.8799\n",
            "Epoch 83/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8662 - val_loss: 0.2925 - val_accuracy: 0.8849\n",
            "Epoch 84/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8710 - val_loss: 0.3192 - val_accuracy: 0.8663\n",
            "Epoch 85/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8671 - val_loss: 0.2958 - val_accuracy: 0.8680\n",
            "Epoch 86/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3151 - accuracy: 0.8669 - val_loss: 0.2823 - val_accuracy: 0.8849\n",
            "Epoch 87/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3207 - accuracy: 0.8667 - val_loss: 0.2874 - val_accuracy: 0.8782\n",
            "Epoch 88/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3136 - accuracy: 0.8657 - val_loss: 0.2946 - val_accuracy: 0.8773\n",
            "Epoch 89/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8651 - val_loss: 0.2907 - val_accuracy: 0.8832\n",
            "Epoch 90/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8660 - val_loss: 0.2853 - val_accuracy: 0.8849\n",
            "Epoch 91/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3205 - accuracy: 0.8644 - val_loss: 0.2846 - val_accuracy: 0.8706\n",
            "Epoch 92/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8714 - val_loss: 0.2972 - val_accuracy: 0.8663\n",
            "Epoch 93/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8672 - val_loss: 0.2934 - val_accuracy: 0.8799\n",
            "Epoch 94/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.8585 - val_loss: 0.2851 - val_accuracy: 0.8841\n",
            "Epoch 95/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3101 - accuracy: 0.8703 - val_loss: 0.2841 - val_accuracy: 0.8739\n",
            "Epoch 96/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3140 - accuracy: 0.8653 - val_loss: 0.2883 - val_accuracy: 0.8756\n",
            "Epoch 97/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3120 - accuracy: 0.8700 - val_loss: 0.2811 - val_accuracy: 0.8824\n",
            "Epoch 98/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3142 - accuracy: 0.8679 - val_loss: 0.2948 - val_accuracy: 0.8756\n",
            "Epoch 99/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.8720 - val_loss: 0.2918 - val_accuracy: 0.8697\n",
            "Epoch 100/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3202 - accuracy: 0.8671 - val_loss: 0.2825 - val_accuracy: 0.8832\n",
            "Epoch 101/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3083 - accuracy: 0.8730 - val_loss: 0.2980 - val_accuracy: 0.8816\n",
            "Epoch 102/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3065 - accuracy: 0.8747 - val_loss: 0.2950 - val_accuracy: 0.8849\n",
            "Epoch 103/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3079 - accuracy: 0.8695 - val_loss: 0.2906 - val_accuracy: 0.8646\n",
            "Epoch 104/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.8730 - val_loss: 0.2845 - val_accuracy: 0.8739\n",
            "Epoch 105/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.8665 - val_loss: 0.2885 - val_accuracy: 0.8663\n",
            "Epoch 106/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3053 - accuracy: 0.8710 - val_loss: 0.2840 - val_accuracy: 0.8824\n",
            "Epoch 107/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3099 - accuracy: 0.8663 - val_loss: 0.2938 - val_accuracy: 0.8756\n",
            "Epoch 108/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.8703 - val_loss: 0.2810 - val_accuracy: 0.8875\n",
            "Epoch 109/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8682 - val_loss: 0.2792 - val_accuracy: 0.8756\n",
            "Epoch 110/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3071 - accuracy: 0.8742 - val_loss: 0.2846 - val_accuracy: 0.8849\n",
            "Epoch 111/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3119 - accuracy: 0.8675 - val_loss: 0.2873 - val_accuracy: 0.8875\n",
            "Epoch 112/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8650 - val_loss: 0.2975 - val_accuracy: 0.8849\n",
            "Epoch 113/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.8702 - val_loss: 0.2915 - val_accuracy: 0.8646\n",
            "Epoch 114/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8685 - val_loss: 0.2894 - val_accuracy: 0.8714\n",
            "Epoch 115/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3163 - accuracy: 0.8707 - val_loss: 0.2842 - val_accuracy: 0.8824\n",
            "Epoch 116/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8692 - val_loss: 0.2961 - val_accuracy: 0.8706\n",
            "Epoch 117/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.8710 - val_loss: 0.2934 - val_accuracy: 0.8723\n",
            "Epoch 118/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3136 - accuracy: 0.8718 - val_loss: 0.2833 - val_accuracy: 0.8714\n",
            "Epoch 119/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3157 - accuracy: 0.8716 - val_loss: 0.2797 - val_accuracy: 0.8841\n",
            "Epoch 120/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.8630 - val_loss: 0.2805 - val_accuracy: 0.8866\n",
            "Epoch 121/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.8652 - val_loss: 0.2861 - val_accuracy: 0.8663\n",
            "Epoch 122/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2990 - accuracy: 0.8775 - val_loss: 0.2874 - val_accuracy: 0.8773\n",
            "Epoch 123/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3143 - accuracy: 0.8706 - val_loss: 0.3046 - val_accuracy: 0.8621\n",
            "Epoch 124/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8756 - val_loss: 0.2796 - val_accuracy: 0.8866\n",
            "Epoch 125/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8702 - val_loss: 0.2781 - val_accuracy: 0.8875\n",
            "Epoch 126/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3132 - accuracy: 0.8692 - val_loss: 0.2807 - val_accuracy: 0.8824\n",
            "Epoch 127/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.8754 - val_loss: 0.2913 - val_accuracy: 0.8790\n",
            "Epoch 128/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3175 - accuracy: 0.8666 - val_loss: 0.2811 - val_accuracy: 0.8858\n",
            "Epoch 129/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3087 - accuracy: 0.8781 - val_loss: 0.2909 - val_accuracy: 0.8697\n",
            "Epoch 130/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8717 - val_loss: 0.2882 - val_accuracy: 0.8841\n",
            "Epoch 131/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.8760 - val_loss: 0.2996 - val_accuracy: 0.8638\n",
            "Epoch 132/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3089 - accuracy: 0.8773 - val_loss: 0.2926 - val_accuracy: 0.8849\n",
            "Epoch 133/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8740 - val_loss: 0.2938 - val_accuracy: 0.8790\n",
            "Epoch 134/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3100 - accuracy: 0.8676 - val_loss: 0.2826 - val_accuracy: 0.8723\n",
            "Epoch 135/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3112 - accuracy: 0.8730 - val_loss: 0.2849 - val_accuracy: 0.8739\n",
            "Epoch 136/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.8831 - val_loss: 0.2944 - val_accuracy: 0.8756\n",
            "Epoch 137/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3053 - accuracy: 0.8716 - val_loss: 0.2872 - val_accuracy: 0.8875\n",
            "Epoch 138/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3136 - accuracy: 0.8684 - val_loss: 0.2926 - val_accuracy: 0.8756\n",
            "Epoch 139/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3118 - accuracy: 0.8674 - val_loss: 0.2975 - val_accuracy: 0.8706\n",
            "Epoch 140/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3116 - accuracy: 0.8692 - val_loss: 0.2893 - val_accuracy: 0.8663\n",
            "Epoch 141/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3105 - accuracy: 0.8708 - val_loss: 0.2923 - val_accuracy: 0.8782\n",
            "Epoch 142/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3095 - accuracy: 0.8698 - val_loss: 0.2849 - val_accuracy: 0.8816\n",
            "Epoch 143/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8679 - val_loss: 0.2837 - val_accuracy: 0.8824\n",
            "Epoch 144/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3171 - accuracy: 0.8683 - val_loss: 0.2847 - val_accuracy: 0.8883\n",
            "Epoch 145/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3072 - accuracy: 0.8709 - val_loss: 0.2830 - val_accuracy: 0.8756\n",
            "Epoch 146/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8720 - val_loss: 0.2838 - val_accuracy: 0.8748\n",
            "Epoch 147/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8771 - val_loss: 0.2900 - val_accuracy: 0.8799\n",
            "Epoch 148/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3095 - accuracy: 0.8747 - val_loss: 0.2988 - val_accuracy: 0.8689\n",
            "Epoch 149/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8718 - val_loss: 0.2909 - val_accuracy: 0.8832\n",
            "Epoch 150/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3087 - accuracy: 0.8712 - val_loss: 0.2858 - val_accuracy: 0.8739\n",
            "Epoch 151/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3034 - accuracy: 0.8741 - val_loss: 0.2909 - val_accuracy: 0.8697\n",
            "Epoch 152/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3084 - accuracy: 0.8760 - val_loss: 0.2813 - val_accuracy: 0.8773\n",
            "Epoch 153/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3103 - accuracy: 0.8738 - val_loss: 0.3030 - val_accuracy: 0.8663\n",
            "Epoch 154/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3136 - accuracy: 0.8665 - val_loss: 0.2854 - val_accuracy: 0.8841\n",
            "Epoch 155/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3077 - accuracy: 0.8776 - val_loss: 0.2849 - val_accuracy: 0.8824\n",
            "Epoch 156/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.8698 - val_loss: 0.2814 - val_accuracy: 0.8858\n",
            "Epoch 157/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3042 - accuracy: 0.8736 - val_loss: 0.2776 - val_accuracy: 0.8748\n",
            "Epoch 158/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8705 - val_loss: 0.2836 - val_accuracy: 0.8799\n",
            "Epoch 159/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8735 - val_loss: 0.2843 - val_accuracy: 0.8832\n",
            "Epoch 160/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8706 - val_loss: 0.2929 - val_accuracy: 0.8748\n",
            "Epoch 161/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3087 - accuracy: 0.8740 - val_loss: 0.2925 - val_accuracy: 0.8756\n",
            "Epoch 162/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3134 - accuracy: 0.8711 - val_loss: 0.2927 - val_accuracy: 0.8799\n",
            "Epoch 163/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3132 - accuracy: 0.8684 - val_loss: 0.2942 - val_accuracy: 0.8773\n",
            "Epoch 164/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3135 - accuracy: 0.8701 - val_loss: 0.2780 - val_accuracy: 0.8849\n",
            "Epoch 165/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2999 - accuracy: 0.8745 - val_loss: 0.2959 - val_accuracy: 0.8756\n",
            "Epoch 166/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8734 - val_loss: 0.2867 - val_accuracy: 0.8807\n",
            "Epoch 167/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3092 - accuracy: 0.8640 - val_loss: 0.2880 - val_accuracy: 0.8824\n",
            "Epoch 168/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.8735 - val_loss: 0.2907 - val_accuracy: 0.8748\n",
            "Epoch 169/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3089 - accuracy: 0.8695 - val_loss: 0.2879 - val_accuracy: 0.8706\n",
            "Epoch 170/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2981 - accuracy: 0.8817 - val_loss: 0.2872 - val_accuracy: 0.8875\n",
            "Epoch 171/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3068 - accuracy: 0.8702 - val_loss: 0.2888 - val_accuracy: 0.8858\n",
            "Epoch 172/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.8744 - val_loss: 0.2863 - val_accuracy: 0.8824\n",
            "Epoch 173/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.8671 - val_loss: 0.2985 - val_accuracy: 0.8697\n",
            "Epoch 174/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8707 - val_loss: 0.2907 - val_accuracy: 0.8655\n",
            "Epoch 175/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.8744 - val_loss: 0.2887 - val_accuracy: 0.8841\n",
            "Epoch 176/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3224 - accuracy: 0.8684 - val_loss: 0.2807 - val_accuracy: 0.8841\n",
            "Epoch 177/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3079 - accuracy: 0.8758 - val_loss: 0.2866 - val_accuracy: 0.8748\n",
            "Epoch 178/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3087 - accuracy: 0.8727 - val_loss: 0.2788 - val_accuracy: 0.8756\n",
            "Epoch 179/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8689 - val_loss: 0.2870 - val_accuracy: 0.8748\n",
            "Epoch 180/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3060 - accuracy: 0.8786 - val_loss: 0.2917 - val_accuracy: 0.8748\n",
            "Epoch 181/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3125 - accuracy: 0.8708 - val_loss: 0.2820 - val_accuracy: 0.8858\n",
            "Epoch 182/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2955 - accuracy: 0.8750 - val_loss: 0.2903 - val_accuracy: 0.8824\n",
            "Epoch 183/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3062 - accuracy: 0.8745 - val_loss: 0.2785 - val_accuracy: 0.8816\n",
            "Epoch 184/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3095 - accuracy: 0.8713 - val_loss: 0.2874 - val_accuracy: 0.8883\n",
            "Epoch 185/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3116 - accuracy: 0.8722 - val_loss: 0.2885 - val_accuracy: 0.8799\n",
            "Epoch 186/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8719 - val_loss: 0.2856 - val_accuracy: 0.8849\n",
            "Epoch 187/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3096 - accuracy: 0.8738 - val_loss: 0.2929 - val_accuracy: 0.8841\n",
            "Epoch 188/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3136 - accuracy: 0.8715 - val_loss: 0.2914 - val_accuracy: 0.8866\n",
            "Epoch 189/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3138 - accuracy: 0.8724 - val_loss: 0.3064 - val_accuracy: 0.8706\n",
            "Epoch 190/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3177 - accuracy: 0.8639 - val_loss: 0.2918 - val_accuracy: 0.8756\n",
            "Epoch 191/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3009 - accuracy: 0.8760 - val_loss: 0.2834 - val_accuracy: 0.8756\n",
            "Epoch 192/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3056 - accuracy: 0.8692 - val_loss: 0.2780 - val_accuracy: 0.8807\n",
            "Epoch 193/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3081 - accuracy: 0.8741 - val_loss: 0.2929 - val_accuracy: 0.8731\n",
            "Epoch 194/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3097 - accuracy: 0.8704 - val_loss: 0.3069 - val_accuracy: 0.8807\n",
            "Epoch 195/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3115 - accuracy: 0.8724 - val_loss: 0.3054 - val_accuracy: 0.8765\n",
            "Epoch 196/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3164 - accuracy: 0.8687 - val_loss: 0.2862 - val_accuracy: 0.8773\n",
            "Epoch 197/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3117 - accuracy: 0.8724 - val_loss: 0.2841 - val_accuracy: 0.8790\n",
            "Epoch 198/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3012 - accuracy: 0.8706 - val_loss: 0.2873 - val_accuracy: 0.8849\n",
            "Epoch 199/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3159 - accuracy: 0.8675 - val_loss: 0.2832 - val_accuracy: 0.8697\n",
            "Epoch 200/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8696 - val_loss: 0.3241 - val_accuracy: 0.8596\n",
            "Epoch 201/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8668 - val_loss: 0.2933 - val_accuracy: 0.8723\n",
            "Epoch 202/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3214 - accuracy: 0.8606 - val_loss: 0.2844 - val_accuracy: 0.8782\n",
            "Epoch 203/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8754 - val_loss: 0.2883 - val_accuracy: 0.8739\n",
            "Epoch 204/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3020 - accuracy: 0.8761 - val_loss: 0.2804 - val_accuracy: 0.8824\n",
            "Epoch 205/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3099 - accuracy: 0.8723 - val_loss: 0.2775 - val_accuracy: 0.8824\n",
            "Epoch 206/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3080 - accuracy: 0.8708 - val_loss: 0.2860 - val_accuracy: 0.8714\n",
            "Epoch 207/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.8725 - val_loss: 0.2950 - val_accuracy: 0.8629\n",
            "Epoch 208/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3068 - accuracy: 0.8754 - val_loss: 0.3035 - val_accuracy: 0.8799\n",
            "Epoch 209/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3077 - accuracy: 0.8740 - val_loss: 0.2819 - val_accuracy: 0.8765\n",
            "Epoch 210/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3027 - accuracy: 0.8747 - val_loss: 0.2809 - val_accuracy: 0.8824\n",
            "Epoch 211/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3044 - accuracy: 0.8726 - val_loss: 0.2840 - val_accuracy: 0.8799\n",
            "Epoch 212/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3092 - accuracy: 0.8715 - val_loss: 0.2866 - val_accuracy: 0.8731\n",
            "Epoch 213/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3193 - accuracy: 0.8660 - val_loss: 0.2803 - val_accuracy: 0.8858\n",
            "Epoch 214/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.8780 - val_loss: 0.2818 - val_accuracy: 0.8832\n",
            "Epoch 215/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2990 - accuracy: 0.8760 - val_loss: 0.2781 - val_accuracy: 0.8807\n",
            "Epoch 216/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.8686 - val_loss: 0.2815 - val_accuracy: 0.8689\n",
            "Epoch 217/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3013 - accuracy: 0.8769 - val_loss: 0.2806 - val_accuracy: 0.8782\n",
            "Epoch 218/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8711 - val_loss: 0.2937 - val_accuracy: 0.8723\n",
            "Epoch 219/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8708 - val_loss: 0.2925 - val_accuracy: 0.8841\n",
            "Epoch 220/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3088 - accuracy: 0.8709 - val_loss: 0.2949 - val_accuracy: 0.8723\n",
            "Epoch 221/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8708 - val_loss: 0.2843 - val_accuracy: 0.8782\n",
            "Epoch 222/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3074 - accuracy: 0.8679 - val_loss: 0.2784 - val_accuracy: 0.8773\n",
            "Epoch 223/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3054 - accuracy: 0.8714 - val_loss: 0.2858 - val_accuracy: 0.8680\n",
            "Epoch 224/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8734 - val_loss: 0.2984 - val_accuracy: 0.8706\n",
            "Epoch 225/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8710 - val_loss: 0.2975 - val_accuracy: 0.8723\n",
            "Epoch 226/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3074 - accuracy: 0.8695 - val_loss: 0.2878 - val_accuracy: 0.8697\n",
            "Epoch 227/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3005 - accuracy: 0.8753 - val_loss: 0.2805 - val_accuracy: 0.8739\n",
            "Epoch 228/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3158 - accuracy: 0.8665 - val_loss: 0.2813 - val_accuracy: 0.8832\n",
            "Epoch 229/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3061 - accuracy: 0.8721 - val_loss: 0.2973 - val_accuracy: 0.8672\n",
            "Epoch 230/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3116 - accuracy: 0.8701 - val_loss: 0.2877 - val_accuracy: 0.8731\n",
            "Epoch 231/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.8806 - val_loss: 0.2782 - val_accuracy: 0.8816\n",
            "Epoch 232/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8685 - val_loss: 0.2872 - val_accuracy: 0.8824\n",
            "Epoch 233/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3124 - accuracy: 0.8677 - val_loss: 0.2939 - val_accuracy: 0.8782\n",
            "Epoch 234/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8763 - val_loss: 0.2855 - val_accuracy: 0.8858\n",
            "Epoch 235/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8717 - val_loss: 0.2790 - val_accuracy: 0.8866\n",
            "Epoch 236/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8734 - val_loss: 0.2924 - val_accuracy: 0.8697\n",
            "Epoch 237/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.8760 - val_loss: 0.2933 - val_accuracy: 0.8731\n",
            "Epoch 238/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3071 - accuracy: 0.8744 - val_loss: 0.2816 - val_accuracy: 0.8765\n",
            "Epoch 239/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8727 - val_loss: 0.2928 - val_accuracy: 0.8731\n",
            "Epoch 240/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3057 - accuracy: 0.8696 - val_loss: 0.2773 - val_accuracy: 0.8748\n",
            "Epoch 241/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3098 - accuracy: 0.8735 - val_loss: 0.2844 - val_accuracy: 0.8816\n",
            "Epoch 242/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.8732 - val_loss: 0.2814 - val_accuracy: 0.8816\n",
            "Epoch 243/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.8663 - val_loss: 0.2823 - val_accuracy: 0.8883\n",
            "Epoch 244/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3002 - accuracy: 0.8786 - val_loss: 0.2779 - val_accuracy: 0.8799\n",
            "Epoch 245/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3086 - accuracy: 0.8721 - val_loss: 0.2803 - val_accuracy: 0.8773\n",
            "Epoch 246/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3130 - accuracy: 0.8660 - val_loss: 0.2738 - val_accuracy: 0.8816\n",
            "Epoch 247/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3055 - accuracy: 0.8696 - val_loss: 0.2964 - val_accuracy: 0.8748\n",
            "Epoch 248/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8752 - val_loss: 0.2881 - val_accuracy: 0.8807\n",
            "Epoch 249/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2974 - accuracy: 0.8718 - val_loss: 0.2756 - val_accuracy: 0.8807\n",
            "Epoch 250/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3062 - accuracy: 0.8750 - val_loss: 0.2822 - val_accuracy: 0.8714\n",
            "Epoch 251/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8713 - val_loss: 0.2820 - val_accuracy: 0.8790\n",
            "Epoch 252/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3076 - accuracy: 0.8714 - val_loss: 0.2828 - val_accuracy: 0.8756\n",
            "Epoch 253/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3136 - accuracy: 0.8718 - val_loss: 0.2792 - val_accuracy: 0.8816\n",
            "Epoch 254/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8802 - val_loss: 0.2925 - val_accuracy: 0.8824\n",
            "Epoch 255/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8727 - val_loss: 0.2849 - val_accuracy: 0.8799\n",
            "Epoch 256/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2987 - accuracy: 0.8755 - val_loss: 0.2825 - val_accuracy: 0.8756\n",
            "Epoch 257/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3105 - accuracy: 0.8743 - val_loss: 0.2806 - val_accuracy: 0.8782\n",
            "Epoch 258/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.8697 - val_loss: 0.2866 - val_accuracy: 0.8773\n",
            "Epoch 259/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.8745 - val_loss: 0.2886 - val_accuracy: 0.8723\n",
            "Epoch 260/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3062 - accuracy: 0.8713 - val_loss: 0.2897 - val_accuracy: 0.8756\n",
            "Epoch 261/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2989 - accuracy: 0.8744 - val_loss: 0.2872 - val_accuracy: 0.8714\n",
            "Epoch 262/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2930 - accuracy: 0.8784 - val_loss: 0.3039 - val_accuracy: 0.8756\n",
            "Epoch 263/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3056 - accuracy: 0.8731 - val_loss: 0.2874 - val_accuracy: 0.8883\n",
            "Epoch 264/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3012 - accuracy: 0.8713 - val_loss: 0.2824 - val_accuracy: 0.8723\n",
            "Epoch 265/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8651 - val_loss: 0.2889 - val_accuracy: 0.8816\n",
            "Epoch 266/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3077 - accuracy: 0.8722 - val_loss: 0.2910 - val_accuracy: 0.8765\n",
            "Epoch 267/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3008 - accuracy: 0.8775 - val_loss: 0.2846 - val_accuracy: 0.8841\n",
            "Epoch 268/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2962 - accuracy: 0.8767 - val_loss: 0.3075 - val_accuracy: 0.8731\n",
            "Epoch 269/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3069 - accuracy: 0.8730 - val_loss: 0.2818 - val_accuracy: 0.8849\n",
            "Epoch 270/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8754 - val_loss: 0.2905 - val_accuracy: 0.8875\n",
            "Epoch 271/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3097 - accuracy: 0.8771 - val_loss: 0.2949 - val_accuracy: 0.8858\n",
            "Epoch 272/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8745 - val_loss: 0.2838 - val_accuracy: 0.8866\n",
            "Epoch 273/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2957 - accuracy: 0.8780 - val_loss: 0.2818 - val_accuracy: 0.8790\n",
            "Epoch 274/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3062 - accuracy: 0.8733 - val_loss: 0.2863 - val_accuracy: 0.8824\n",
            "Epoch 275/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.8709 - val_loss: 0.2859 - val_accuracy: 0.8782\n",
            "Epoch 276/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8665 - val_loss: 0.2859 - val_accuracy: 0.8824\n",
            "Epoch 277/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3080 - accuracy: 0.8720 - val_loss: 0.2844 - val_accuracy: 0.8866\n",
            "Epoch 278/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.8734 - val_loss: 0.2822 - val_accuracy: 0.8841\n",
            "Epoch 279/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.8721 - val_loss: 0.2895 - val_accuracy: 0.8731\n",
            "Epoch 280/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3132 - accuracy: 0.8685 - val_loss: 0.2944 - val_accuracy: 0.8689\n",
            "Epoch 281/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3066 - accuracy: 0.8759 - val_loss: 0.2782 - val_accuracy: 0.8849\n",
            "Epoch 282/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3065 - accuracy: 0.8733 - val_loss: 0.2795 - val_accuracy: 0.8756\n",
            "Epoch 283/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8737 - val_loss: 0.2808 - val_accuracy: 0.8816\n",
            "Epoch 284/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2986 - accuracy: 0.8756 - val_loss: 0.2863 - val_accuracy: 0.8858\n",
            "Epoch 285/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3027 - accuracy: 0.8778 - val_loss: 0.2837 - val_accuracy: 0.8799\n",
            "Epoch 286/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3033 - accuracy: 0.8743 - val_loss: 0.2900 - val_accuracy: 0.8731\n",
            "Epoch 287/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3040 - accuracy: 0.8713 - val_loss: 0.2913 - val_accuracy: 0.8689\n",
            "Epoch 288/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.2970 - accuracy: 0.8798 - val_loss: 0.2821 - val_accuracy: 0.8773\n",
            "Epoch 289/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3159 - accuracy: 0.8655 - val_loss: 0.2847 - val_accuracy: 0.8773\n",
            "Epoch 290/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3008 - accuracy: 0.8750 - val_loss: 0.2915 - val_accuracy: 0.8739\n",
            "Epoch 291/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3038 - accuracy: 0.8784 - val_loss: 0.2868 - val_accuracy: 0.8892\n",
            "Epoch 292/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3075 - accuracy: 0.8673 - val_loss: 0.2800 - val_accuracy: 0.8782\n",
            "Epoch 293/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3145 - accuracy: 0.8690 - val_loss: 0.2761 - val_accuracy: 0.8816\n",
            "Epoch 294/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3137 - accuracy: 0.8712 - val_loss: 0.2786 - val_accuracy: 0.8739\n",
            "Epoch 295/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8734 - val_loss: 0.2822 - val_accuracy: 0.8773\n",
            "Epoch 296/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3030 - accuracy: 0.8786 - val_loss: 0.2851 - val_accuracy: 0.8756\n",
            "Epoch 297/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3001 - accuracy: 0.8771 - val_loss: 0.2861 - val_accuracy: 0.8832\n",
            "Epoch 298/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3153 - accuracy: 0.8730 - val_loss: 0.2826 - val_accuracy: 0.8765\n",
            "Epoch 299/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3041 - accuracy: 0.8747 - val_loss: 0.2952 - val_accuracy: 0.8900\n",
            "Epoch 300/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8678 - val_loss: 0.2840 - val_accuracy: 0.8731\n",
            "Epoch 301/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8667 - val_loss: 0.2826 - val_accuracy: 0.8748\n",
            "Epoch 302/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3019 - accuracy: 0.8807 - val_loss: 0.2782 - val_accuracy: 0.8858\n",
            "Epoch 303/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8682 - val_loss: 0.2895 - val_accuracy: 0.8799\n",
            "Epoch 304/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3037 - accuracy: 0.8746 - val_loss: 0.2856 - val_accuracy: 0.8883\n",
            "Epoch 305/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3124 - accuracy: 0.8673 - val_loss: 0.2794 - val_accuracy: 0.8824\n",
            "Epoch 306/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3050 - accuracy: 0.8786 - val_loss: 0.2842 - val_accuracy: 0.8824\n",
            "Epoch 307/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3075 - accuracy: 0.8747 - val_loss: 0.2901 - val_accuracy: 0.8739\n",
            "Epoch 308/1000\n",
            "333/333 [==============================] - 1s 2ms/step - loss: 0.3135 - accuracy: 0.8767 - val_loss: 0.2903 - val_accuracy: 0.8773\n",
            "Time elapsed : 186.02279615402222\n",
            "time: 3min 6s (started: 2020-12-22 02:26:48 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTfFswgRSdcL"
      },
      "source": [
        "Visualisasi nilai loss untuk setiap epoch sepanjang iterasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvQEnHeugMnj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0ca26838-4a3d-4ce6-87a4-d3a230878b4f"
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\r\n",
        "plt.plot(history.history['val_loss'], label='test')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "time: 174 ms (started: 2020-12-22 02:30:19 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnrVDw-WRDXg"
      },
      "source": [
        "Mengecek akurasi untuk data test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2LOOHGTjQRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4540c37-7dce-407c-9206-1889e63f9e4e"
      },
      "source": [
        "preds = model.predict(X_test_reshaped)\r\n",
        "preds = np.round(preds, 0).reshape(preds.shape[0])\r\n",
        "acc = accuracy_score(y_test, preds)\r\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8798646362098139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "stream",
          "text": [
            "time: 141 ms (started: 2020-12-22 02:30:22 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPZLTlBURI9v"
      },
      "source": [
        "Mengecek akurasi untuk data train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jlfGxtprtqi",
        "outputId": "dcdd0999-9da6-45dc-92eb-e8fd3d7c5adb"
      },
      "source": [
        "preds = model.predict(X_train_reshaped)\r\n",
        "preds = np.round(preds, 0).reshape(preds.shape[0])\r\n",
        "acc = accuracy_score(y_train, preds)\r\n",
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8857438405115666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        },
        {
          "output_type": "stream",
          "text": [
            "time: 261 ms (started: 2020-12-22 02:30:24 +00:00)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}